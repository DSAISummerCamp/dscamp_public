{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Linear_models_instructor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SW3hrjcjXva"
      },
      "source": [
        "# Linear models (Instructor Notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Diw-JJ7lmOLC"
      },
      "source": [
        "## **Scikit-Learn Regression Example**\n",
        "\n",
        "In this example, we train a linear regression model to predict disease progression one year after baseline.\n",
        "\n",
        "There are ten baseline variables: age, sex, body mass index (BMI), average blood pressure, and six bvlood serum measurements for n = 442 diabetic patients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql1Nfy5TmTsm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes = datasets.load_diabetes()\n",
        "\n",
        "# Use only one feature\n",
        "diabetes_X = diabetes.data[:, np.newaxis, 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nimTfwr9nAqn"
      },
      "source": [
        "Split the data set into training and testing sets, by dropping the last 20 observations for the training set (402 observations for training) and keeping the last 20 observations for the testing set (20 observations for testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll5A8pF6nA_C"
      },
      "source": [
        "# Split the data into training/testing sets\n",
        "diabetes_X_train = diabetes_X[:-20]\n",
        "diabetes_X_test = diabetes_X[-20:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "diabetes_y_train = diabetes.target[:-20]\n",
        "diabetes_y_test = diabetes.target[-20:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBRsN_YEnRxR"
      },
      "source": [
        "Create and train the linear regression object, and make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nm_Yy9hnSGq"
      },
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Traing the model using the training sets\n",
        "regr.fit(diabetes_X_train, diabetes_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "diabetes_y_pred = regr.predict(diabetes_X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTUM_NPSnZ2l"
      },
      "source": [
        "Output the estimated linear regression coefficients, the mean squared error, and the coefficient of determination (variance score) to understand model fit\n",
        "\n",
        "Also plot the prediction outputs to visualize model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "EBxnW4lonaQv",
        "outputId": "e96fbfd8-491f-41c9-9643-c379dd77bde2"
      },
      "source": [
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f' % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
        "\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_X_test, diabetes_y_test, color = 'black')\n",
        "plt.plot(diabetes_X_test, diabetes_y_pred, color = 'blue', linewidth = 3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: \n",
            " [938.23786125]\n",
            "Mean squared error: 2548.07\n",
            "Variance score: 0.47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQfElEQVR4nO3dbagcZ93H8d9sE2L2pmlMk1hEdkZj09aHIuTUgIjV6G31za1Rmhu7KiTUbREqlFpfuIJCuwqiRRSi3ahUOPNCG4IPL7Slqe2LQO94UqhaKyaNOxuktDX0Cfc0Tzv3i+meycOe3Zk9O3vNXPP9QF5kuM45V9LTX/7nf838xwnDUACA2auY3gAAlBUBDACGEMAAYAgBDACGEMAAYAgBDACGrEqzeOPGjaHneRltBQDsdOTIkX+HYbjp4uupAtjzPC0sLExvVwBQAo7jBMOu04IAAEMIYAAwhAAGAEMIYAAwhAAGAEMIYABYhu/78jxPlUpFnufJ9/2pfv5Ut6EBQFn4vq9Go6FerydJCoJAjUZDklSv16fyNaiAAWCIZrO5FL4DvV5PzWZzal+DAAaAIbrdbqrrkyCAAWCIWq2W6vokCGAAGKLVaqlarV5wrVqtqtVqTe1rEMAAMES9Xle73ZbrunIcR67rqt1uT+0ATpKcNC/lnJubCxnGAwDpOI5zJAzDuYuvUwEDgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAYQgADgCEEMAAMcfSodM01kuNInic98sj0vwYBDMAavu/L8zxVKhV5niff91N9/KlT0h13RKG7dav0j39E14NAarenv99V0/+UADB7vu+r0Wio1+tJkoIgUKPRkCTV6/WRH/vrX0s7d47+/Hv2TGWbF6ACBmCFZrO5FL4DvV5PzWZz6PoTJ6Qbboiq3VHhe/310vHj0ic+Mc3dRghgAFbodrtjr589KzWbUejWatLCwvKf75e/lMJQeuop6e1vn/ZuIwQwACvUarVlrz/6aBS6q1dL3/728p/jS1+Ser0oeHftymij5yGAAVih1WqpWq2ed2WTKpU/Kgg6+uhHl/84z5OefjoK3XZbWrs2653GOIQDYIV6va5+X7rtts1aXPxvSVK/v/z6n/40OlhznBltcAgCGEDhHTggffazkjT6boddu6R9+6R162ayrbEIYACF9Pzz0lVXjV+3YYP00EPS3Fz2e0qLHjCAwghD6dZbo7bBuPC9+Wbp3Dnp5Ml8hq9EAAOFstInvYrq4MEodCsV6Wc/G722242C+le/itbnGS0IoCBW8qRXEb3ySnSHwssvj1/7i19IX/xi5luaupz/+wBgIO2TXkX19a9H1e769aPD98Mfls6ciardIoavRAUMFEaSJ72K6k9/kt7//mRrn3lGuvbabPczK1TAQEGMetKriBYX43GP48L3vvuiSjcM7QlfiQAGCuPSJ72karWqVqtlaEeTue++KHSr1Xjc4zDXXRc/FnznnbPb3yzRggAKYnDQ1mw21e12VavV1Gq1CnEA98wz0rvelWztwoK0bVu2+8kLJwzDxIvn5ubChVHjgwDgDWfOSB/5iHTo0Pi1zaZ0773Z78kUx3GOhGF4yd3IVMAApuqBB6Tdu8evu/JK6dlnpSuuyHxLuUUAA1ixbldy3WRrDx6UduzIdj9FwSEcgIn0+9JnPhMdqI0L39tui9aHIeF7PipgAKn85jfSpz+dbO3zz0ubN2e7nyKjAgYw1rPPRpWu44wP3wMH4nt2Cd/RqIABDBWG0qpVo4eaD+zcKe3fn//hN3nDXxeAC+zdG08eGxe+nU4U1AcOEL6ToAIGkHi4uRSNg9yzJ9v9lAUBDJTY1q3S0aPJ1i4uSm96U7b7KRt+aABKZv/++EBtXPg+/HB8oEb4Th8VMFACr72W/EWUH/qQ9Pjj2e4HESpgwGI33RRVuknC96WXokqX8J0dAhiwzGOPxS2Ghx8evXZ+Pm4xrF8/k+3hPLQgAAucPi2tWZNs7dveJp04ke1+kAwVMFBgjUZU6SYJ33/9K6p0Cd/8IICBgnnqqbjFsG/f6LXf/37cYnjrW2ezPyRHCwIogHPnoseCk+r3o4BGvlEBAzn2qU9FQZokfP/+97jaJXyLgQAGcuYvf4lbDL/97ei1X/1qHLrXXDOb/WF6aEEAORCG6YbZnD4trV6d3X4wG9ZXwL7vy/M8VSoVeZ4n3/dNbwlYcued8eSxcX73u7jaJXztYHUF7Pu+Go2Ger2eJCkIAjUaDUkqxKu8YacTJ6RaLdnaTZukF17Idj8wx+rX0nuepyAILrnuuq46nc7sN4RSS3Mw9uqr0uWXZ7cXzNZyr6W3ugXR7XZTXQfON4321Q9+EB+ojXP//XGLgfAtB6tbELVabWgFXEv68x9KayXtq5dflt785uRfK8UPobCM1RVwq9VStVq94Fq1WlWr1TK0IxRFs9lcCt+BXq+nZrO57MesWRNVuknC97nn4moX5WV1ANfrdbXbbbmuK8dx5Lqu2u02B3AYK2n76sEH4xbD6dOjP+c3vhGHbtLX/8BuVgewFIVwp9NRv99Xp9MhfJHIcm2qWq2mU6fi0N21a/znGoTuPfdMeZMzxO2c2bA+gIFJDGtfOc5TCoJOolfznP9YcNEN+uFBECgMw6V+OCG8cgQwMMSgfbV58y2SQkmhwvD6MR9j52PBk/TDkYzVd0EAk+j3pcsuk6T6G7/Gr7d5+A23c2aHChh4w9VXR0Eahe9ohw6VZ/LYqH44VoYARqkdPhwfqB07Nnrt9u1x6H7gA7PZXx5wO2d2aEGglNJUrYuLSnTwZqvBnUPNZlPdble1Wk2tVos7iqaAChilsXNn8seCf/zjuNotc/gOcDtnNqiAYbXjx6UtW5Kvt+G2MRQHAQwrpWkxnDwpbdiQ3V6A5dCCgDU+97nkLYavfS1uMRC+MIUKGIX2wgvSW96SfD0tBuQJFTAKaVDpJgnfv/3NnseCYRcCGIVxzz3JWwzXXhuH7nXXZb83YBK0IJBri4vSRc8AjESViyKhAkYuDSrdJOF78CAtBhQTAZwR5qemt3dv8haDFIfujh3Z7gvICi2IDKzkfWJlE08eS+bs2XTrgTyjAs4A81PHG1S6ScL05z+Pq13CFzahAs4A81OH+8MfpE9+Mvl6erqwHQGcgVqtpiAIhl4vozSPBb/6qnT55dntBcgTWhAZYH6qtG5d8gO1PXviFgPhizKhAs5AWeenPv209J73JF9PiwFl54Qp/i+Ym5sLFxYWMtwOiihNiyEIpJJ2YlBijuMcCcNw7uLrtCAwkY99LHmL4X3vi1sMhC8QowWBxJg8BkwXFTDGSjN57PBhHgsGkiKAMdRdd032WPANN2S7L8AmtCCw5NSpdC+g7PfTHcABuBAVMJYq3STh++CDcbVL+AIrQwVcUvv3SzffnHw9PV1g+qiAS2RQtTpO0vBdLdf1ND/PKE0gCwRwCaxdG4VuJcF/7d27/0/V6n9JciSdXRqlyTxjYPoIYEs98URc7b7++vj1g77uo4/+L6M0gRmhB2yZlU4eY5QmMDtUwBb44AeT37N7112jJ48tNzKzrKM0gSwRwAX1z3/GoXvo0Pj1g9D93vdGr2OUJjA7BHDBDEL3He8Yv/bEifSPBdfrdbXbbbmuK8dx5Lqu2u229aM0ARMYR1kAt98u3X9/srU33RS9+gdAfiw3jpJDuJx66SVpw4bk63lQAigeWhA54fu+PM9bajEkCd8nn2TyGFBkVMA58IUvLGh+vi5pfJ9106ZoLi+A4iOADTl9WlqzZvC7S1pDl2DyGGAfWhAzNmgxxOE7yv8weQywGAE8A7//fbrh5tEcBkeu++cMdwXANFoQGQnDZMNvBtauvUKLi68u/Z6HHwD7UQFP2e23J5889sMfxncx7Nu3l4cfgJIhgKfg/MeCkzwwMQjdO+6Ir9XrdXU6HfX7fXU6HcJ3Cga39lUqFXmex0hN5A4tiBVY6eQxZMf3fTUajaXRmoO5xpL4xw25QQWc0ne+k/xA7YEHRk8eQ3aazSZzjZF7VMAJnDwpbdyYfD1PppnHXGMUARXwCINKN0n4vvgijwXnCXONUQQE8EXm55O3GO69Nw7dNBVy3tlweMVcYxQBLQhJi4vSRf+vjmRzlWvL4dVgr81mU91uV7VaTa1Wq1B/Btiv1POAr75aOnYs2dpjx6QtW7LdTx54nqcgCC657rquOp3O7DcEWGC5ecCla0E88kjcYhgXvrfeGrcYyhC+EodXwCyVogVx7py0KsWftMyTx2q12tAKmMMrYPqsroC/+c0oSJOE7+HDYvKYOLwCZsm6Cvj48eTtghtvlB57LNPtFA6HV8DsWHEIF4bSl78s/eQnydafOZOuJQEAK2HlIdzjj8eTx8aF7/kthryHrw334QIYL+dRdKnXXpPe+c5k70W75RapaNlly324AMYrTAX8rW9F1e66dePDt9eLKt08hG/aapYhMkB55LoCfvJJadu2ZGv/+lfp3e/Odj9pTVLNch8uUB65q4Bff11673ujandc+H73u3FfN2/hK01WzTJEBiiP3ATwj34Uhe7atVE1u5wtW6T//CcK3bvvnt3+JjFJNct9uEB5GA3go0fjx4K/8pXRa594IgrdY8fSDc4xaZJqtl6vq91u8344oARmHsBnz0o7dkShu3Xr6LV33x23GLZvn83+pmnSapb3wwHlMLNDON+XPv/58evWrZOCQFq/Pvs9ZY2nygCMkvmTcK+8kixMH3pI+vjHU31qACgEY0/CjXpN++7d0eSxMCR8AZRP5i2I7dul1auj+QsDzz0nXXVV1l8ZAPIt8wC+8cYocM+cIXQB4HwzOYS78spZfBUAKJbcPIgBAGVDAAOAIdYEMDN0ARRNrqehJcUMXQBFZEUFzAxdAEVkRQAzQxdAEVkRwMzQLRf6/bCFFQFs+wxdAic26PcHQaAwDJf6/WX+O0GBhWGY+Ne2bdvCvJqfnw9d1w0dxwld1w3n5+dNb2kq5ufnw2q1Gkpa+lWtVhP9+Wz8O3Fd94K/i8Ev13VNbw1YlqSFcEimZj4NDSvjeZ6CILjkuuu66nQ6y37cxXeGSNFPBUUf7l6pVDTse9ZxHPX7fQM7AsYzNg0NKzPpAaOtd4bQ74dNCOCcmzRwbL0zxPZ+P8qFAM65SQPH1kqRd+bBJgRwzk0aODZXirwzD7aYWQBzK9XkJgkcKkUg/2ZyF4StJ/IAkITRuyBsPZEHgJWYSQDbeiIPACsxkwC29UQeAFZiJgFs84k8AEwq8wD2fX+pB3zZZZdJEifyGIk7ZlAWmb4R4+K7H86dO7dU+RK+GIa3m6BMMr0NbdJBMigvvmdgIyO3oXH3A9LiewZlkmkAc/cD0uJ7BmWSaQBz9wPS4nsGZZJpADOPAGnxPYMy4Y0YAJAx3ogBADlDAAOAIQQwABhCAAOAIQQwABiS6i4Ix3FelHTpc6IAgFHcMAw3XXwxVQADAKaHFgQAGEIAA4AhBDAAGEIAA4AhBDAAGEIAA4AhBDAAGEIAA4AhBDAAGPL/Fn14gssvCKAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8IVGCnin2W2"
      },
      "source": [
        "## **Project**\n",
        "\n",
        "Logistic regression to predict ability of a person to repay a loan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-Un8SZTjXvb"
      },
      "source": [
        "\\~\\~\\~\\~\\~\\~\\~\\~\\~__You only need to run next cell once__\\~\\~\\~\\~\\~\\~\\~\\~\\~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eqT-B1pjXvc",
        "outputId": "86653c32-f707-4704-8036-fb99023a2014"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJvNt2FTjXvd"
      },
      "source": [
        "\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDBw4ydwjXve"
      },
      "source": [
        "In this example, students will explore methods of logistic regression, variable selection, and goodness of fit measures. Using the data from social network, students can build different logistic regression models to obtain the best model fit and explore the parameter space to identify drivers affecting the dependent variable.\n",
        "\n",
        "The model uses data generated by _randomize_features.py_. Please refer to the code for details. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJV1AyykjXvf"
      },
      "source": [
        "##\n",
        "# Importing modules and loading the data\n",
        "# Note that statsmodels are used for logistic regression instead of sklearn\n",
        "# The main reason - coefficient significant and testing is not available out of the box for sklearn\n",
        "# There are minor differences in the model specification between logistic regression on statsmodels/sklearn\n",
        "# See package documentation for more details\n",
        "##\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression as logit\n",
        "from sklearn.preprocessing import LabelEncoder as encoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = pd.read_csv('/content/gdrive/My Drive/dscamp/dscamp_public/Linear Models/face_data_inf.csv')\n",
        "RANDOM_SEED = 123"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpF8Qnc5jXvi"
      },
      "source": [
        "The dataset contains a number of fields randomized to generate social network profile:\n",
        "\n",
        "- 'face_id'- id assocated with profile picture\n",
        "- 'age' - age of a person\n",
        "- 'gender' - gender of a person\n",
        "- 'relationship' - marital status (single, married)\n",
        "- 'music_genre' - favourite musical genre (random, pre-defined list)\n",
        "- 'band' - random band name based on 'music_genre' (random, non-existant)\n",
        "- 'team' - favourite team (random, from list of teams)\n",
        "- 'first_name' - random first name\n",
        "- 'last_name' - random last name (relationship=='married' adopts the name of the partner)\n",
        "- 'education' - education level (random conditional on age, pre-defined list)\n",
        "- 'education_prompt' - technical field for web page render\n",
        "- 'work'- employer name (if any, otherwise 'unemployed'; random conditional on 'education', non-existant)\n",
        "- 'work_prompt' - technical field for web page render\n",
        "- 'fav_movie_1' - favourite movie (random based on genre, pre-defined list)\n",
        "- 'fav_movie_2' - favourite movie (random based on genre, pre-defined list; disjoint genre from 'fav_movie_1')\n",
        "- 'fav_book_1' - favourite book (random, pre-defined list)\n",
        "- 'fav_book_2' - favourite book (random, pre-defined list)\n",
        "- 'fav_book_3' - favourite book (random, pre-defined list)\n",
        "- 'fav_auth_1' - favourite book's author (conditional of fav_book_1)\n",
        "- 'fav_auth_2' - favourite book's author (conditional of fav_book_2)\n",
        "- 'fav_auth_3' - favourite book's author (conditional of fav_book_3)\n",
        "- 'fav_food_1' - favourite dish (random, pre-defined list)\n",
        "- 'fav_food_2' - favourite dish (random, pre-defined list)\n",
        "- 'fav_food_3' - favourite dish (random, pre-defined list)\n",
        "- 'home_city' - home town (random US town)\n",
        "- 'home_state' - home state (based on 'home_city')\n",
        "- 'languages' - number of languages person speaks (random, 1-4)\n",
        "- 'hogwarts' - hogwarts house (random, pre-defined list)\n",
        "- 'fav_pet' - favourite pet (random, pre-defined list)\n",
        "- 'vg_genre' - favourite video game genre (random, pre-defined list)\n",
        "- 'fav_video_game' - favourite video game (random, based on 'vg_genre')\n",
        "- 'spouse_id' - 'face_id' of spouse\n",
        "- 'n_friends' - number of friends in the network (degree of a node in the social network graph)\n",
        "- 'credit' - randomly generate binary variable, credit worthiness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHVTUTzwjXvj"
      },
      "source": [
        "Most of the features are completely random, thus are not suitable for regression modeling. Two notable distinctions that can be used for example:\n",
        "\n",
        "- 'n_friends' - if network is generated using 'config' method, then degree distribution follows the Poisson regression specification:\n",
        "\n",
        "$$\n",
        "N_i = exp^{-3+0.1 \\textbf{age}_i+0.3 \\textbf{relationship}_i+0.1 \\textbf{education}_i+0.2 \\textbf{languages}_i}+\\epsilon_i\n",
        "$$\n",
        "\n",
        "where regressors are taken from random dataset (education is binary with 1 for \\[bachelor, master, doctor\\], 0 otherwise) and $\\epsilon$ is a random integer between 1 and 5. Note that the actual degree distribution will be slightly different from the equation due to pre-processing to make a proper graph (with removal of parallel edges and self-loops).\n",
        "\n",
        "- 'credit' - generated with 'generate_infection' function and assumes the following logistic regression specificaiton:\n",
        "\n",
        "$$\n",
        "p_i = \\frac{1}{1+\\exp^{-(-17+0.4 \\textbf{age}_i+ 0.1 \\textbf{n_friends}_i -1.5 \\textbf{work}_i +1 \\textbf{state}_i  + 1.5 \\epsilon_i)}}\n",
        "$$\n",
        "\n",
        "where regressors are taken from the dataset and $\\epsilon$ is a standard normal random variable. 'state' is a discretized variable taking value of 2 if 'home_state' is CA, TX, or FL (highly populous), 1 if 'home_state' is NY, PA, IL, OH, GA, NC (medium populous), and 0 otherwise (low density population states). Variable 'credit' takes value 1 if $p_i>0.5$ and 0 otherwise.\n",
        "\n",
        "Below we consider reproduced model of logistic regression for 'credit variable'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BoGxxozjXvm"
      },
      "source": [
        "##\n",
        "# Generate features from the data\n",
        "##\n",
        "work = data['work'] == 'unemployed'\n",
        "work = [float(i) for i in work]\n",
        "\n",
        "def discretize_state(row):\n",
        "    if row['home_state'] in ['CA', 'TX', 'FL']:\n",
        "        return 2\n",
        "    else:\n",
        "        if row['home_state'] in ['NY', 'OH', 'IL', 'PA', 'GA', 'NC']:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "state = data.apply (lambda row: discretize_state(row), axis=1)\n",
        "data['state'] = state\n",
        "data['employment'] = work\n",
        "X = data[['state', 'employment', 'n_friends', 'age']]\n",
        "y = data['credit']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daKNsAkWjXvo"
      },
      "source": [
        "The logistic regression aims to capture the relationship between financial reliablity/ability to repay debt and a set of social features. The example is motivated by recent efforts to use social network data to infer credit score. The intuitive explanations for the features are as follows:\n",
        "\n",
        "- 'age' affects repayment rate with higher age being more financially stable. (Note - restricted attribute)\n",
        "- 'n_friends' having large node degree suggest higher level of responsibility to meet financial obligations.\n",
        "- 'employment' being unemployed adversely affect the ability to repay one's loan.\n",
        "- 'state' suggests higher density areas provide bigger opportunities to meet one's financial obligations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMcrngQrjXvo"
      },
      "source": [
        "##\n",
        "# Split train test into 80/20 ratio.\n",
        "##\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gus9GDWnjXvq",
        "outputId": "244a6d80-8171-47f2-b70b-369ef4906a4c"
      },
      "source": [
        "##\n",
        "# Fit logistic regression and provide fit summary.\n",
        "##\n",
        "lr = sm.Logit(y_train, sm.add_constant(X_train)).fit()\n",
        "lr.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.146478\n",
            "         Iterations 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>credit</td>      <th>  No. Observations:  </th>   <td>   800</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>   795</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     4</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Wed, 22 Apr 2020</td> <th>  Pseudo R-squ.:     </th>   <td>0.7376</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>15:33:56</td>     <th>  Log-Likelihood:    </th>  <td> -117.18</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -446.54</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.019e-141</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>      <td>  -22.8898</td> <td>    2.358</td> <td>   -9.707</td> <td> 0.000</td> <td>  -27.511</td> <td>  -18.268</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>state</th>      <td>    1.5745</td> <td>    0.275</td> <td>    5.731</td> <td> 0.000</td> <td>    1.036</td> <td>    2.113</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>employment</th> <td>   -2.6158</td> <td>    1.158</td> <td>   -2.259</td> <td> 0.024</td> <td>   -4.886</td> <td>   -0.346</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>n_friends</th>  <td>    0.1144</td> <td>    0.075</td> <td>    1.530</td> <td> 0.126</td> <td>   -0.032</td> <td>    0.261</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>age</th>        <td>    0.5407</td> <td>    0.064</td> <td>    8.415</td> <td> 0.000</td> <td>    0.415</td> <td>    0.667</td>\n",
              "</tr>\n",
              "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.25 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:                 credit   No. Observations:                  800\n",
              "Model:                          Logit   Df Residuals:                      795\n",
              "Method:                           MLE   Df Model:                            4\n",
              "Date:                Wed, 22 Apr 2020   Pseudo R-squ.:                  0.7376\n",
              "Time:                        15:33:56   Log-Likelihood:                -117.18\n",
              "converged:                       True   LL-Null:                       -446.54\n",
              "Covariance Type:            nonrobust   LLR p-value:                3.019e-141\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        -22.8898      2.358     -9.707      0.000     -27.511     -18.268\n",
              "state          1.5745      0.275      5.731      0.000       1.036       2.113\n",
              "employment    -2.6158      1.158     -2.259      0.024      -4.886      -0.346\n",
              "n_friends      0.1144      0.075      1.530      0.126      -0.032       0.261\n",
              "age            0.5407      0.064      8.415      0.000       0.415       0.667\n",
              "==============================================================================\n",
              "\n",
              "Possibly complete quasi-separation: A fraction 0.25 of observations can be\n",
              "perfectly predicted. This might indicate that there is complete\n",
              "quasi-separation. In this case some parameters will not be identified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFmxA-PgjXvs"
      },
      "source": [
        "##\n",
        "# Provide accuracy for the model\n",
        "##\n",
        "y_pred = lr.predict(sm.add_constant(X_test)) > 0.5\n",
        "print(\"Accuracy: \"+ str(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}