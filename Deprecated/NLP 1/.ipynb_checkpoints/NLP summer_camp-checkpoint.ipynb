{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Introduction to Natural Language Processing </center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> What is NLP? </h2> </font> \n",
    "* One of the most challenging and revolutionary things artificial intelligence (AI) can do is speak, write, listen, and understand human language. Natural language processing (NLP) is a form of AI that extracts meaning from human language to make decisions based on the information.  \n",
    "<br>\n",
    "* It is an interdisciplinary field which draws on other areas of study sucj as computer science , Artificial Intelligence, linguistics and logic.\n",
    "\n",
    "<img src=\"images/image001.png\", width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Why NLP Understanding is hard? </h2> </font> \n",
    "* Natural language is extremely rich in form and structure, and very ambiguous.\n",
    "    - How to represent meaning\n",
    "    - Which structures map to which meaning structures.  \n",
    "<br>\n",
    "* One input can mean many different things. Ambiguity can be at different levels.\n",
    "    - Lexical (word level) ambiguity  -- different meanings of words\n",
    "    - Syntactic ambiguity  --  different ways to parse the sentence\n",
    "    - Interpreting partial information  --  how to interpret pronouns\n",
    "    - Contextual information  --  context of the sentence may affect the meaning of that sentence.  \n",
    "<br>\n",
    "* Many input can mean the same thing.  \n",
    "<br>\n",
    "* Interaction among components of the input is not clear. \n",
    "<img src=\"images/image002.png\", width=300>\n",
    "\n",
    "**What Applications of NLP can you think of?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> NLP Applications </h2> </font> \n",
    "<img src=\"images/machine_translation.png\">\n",
    "* Famous application: **Google Translate**\n",
    "<img src=\"images/Picture1.png\">\n",
    "* Movie Reviews: **Positive of Negative**\n",
    "<img src=\"images/Picture2.png\">\n",
    "* Classification of emails: **Important, Spam, etc**\n",
    "<img src=\"images/Picture3.png\">\n",
    "<font> <h3> Speech recognition (Speech-to-text) and Speech Understanding </h3> </font> \n",
    "<img src=\"images/speech_recog.jpeg\", width=300>\n",
    "* Famous application: **Amazon‚Äô s Alexa, Google‚Äôs Home, SIRI**\n",
    "<font> <h3> Text prediction </h3> </font> \n",
    "<img src=\"images/text_pred.png\", width=300>\n",
    "* Speed up word processing and Facilitate text dictation (seen in SMS and email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2>NLP Overview</h2> </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font color='red'> <h2>NLP Pipeline</h2> </font> \n",
    "<font color='black'> <h3>During this class we will work with an example. Write a review of a product of your choice and you will be able to run code examples on your review following the NLP pipeline described below</h3> </font> \n",
    "<img src=\"images/Capture.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Text Pre-processing - ¬†extracting the useful information from the textual data. </h2> </font> \n",
    "* Converting all letters to lower or upper case\n",
    "\n",
    "* Converting numbers into words or removing numbers\n",
    "\n",
    "* Removing punctuations, accent marks and other diacritics\n",
    "\n",
    "* Removing white spaces\n",
    "\n",
    "* Expanding abbreviations\n",
    "\n",
    "* Removing stop words, sparse terms, and particular words\n",
    "\n",
    "** Enter a positive or/and a negative review for a product of your choice and use the functins provided in the notebook to pre-process your review. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"data/nltk_data/\")\n",
    "!cd data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "def convert_to_lower(mytext):\n",
    "    return mytext.lower()\n",
    "def remove_numbers(mytext):\n",
    "    return ''.join([i for i in mytext if not i.isdigit()])\n",
    "def remove_puntuation(mytext):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return ' '.join([w.translate(table) for w in mytext.split()])\n",
    "def remove_white_spaces(mytext):\n",
    "    return ' '.join(mytext.strip().split())\n",
    "def remove_stop_words(mytext):\n",
    "    stop_words = list(stopwords.words('english')) \n",
    "    output =[]\n",
    "    for i in mytext.split():\n",
    "        if not i in stop_words:\n",
    "            output.append(i)\n",
    "    return ' '.join(output)\n",
    "def pre_process(mytext):\n",
    "    mytext_lower = convert_to_lower(mytext)\n",
    "    my_text_char = remove_numbers(mytext_lower)\n",
    "    my_text_no_punct = remove_puntuation(my_text_char)\n",
    "    my_text_white_spaces = remove_white_spaces(my_text_no_punct)\n",
    "    preprocessed_text = remove_stop_words(my_text_white_spaces)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> <h2> Write a product review below and test our pre-processing functions! </h2> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertaining funny\n"
     ]
    }
   ],
   "source": [
    "# You can play with this. Change the texts between the quotes and call the functions to process/clean it! \n",
    "positive_review= \"Very entertaining and funny!\"\n",
    "processed_positive_review = pre_process(positive_review)\n",
    "print(processed_positive_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2>NLP Pipeline</h2> </font> \n",
    "<img src=\"images/Capture2.PNG\", width = 1100>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2>How do we have usable meaning in a computer?</h2> </font> \n",
    "Definition: meaning (Webster dictionary)\n",
    "<br/>\n",
    "‚Ä¢ the idea that is represented by a word, phrase, etc.\n",
    "<br/>\n",
    "‚Ä¢ the idea that a person wants to express by using\n",
    "words, signs, etc.\n",
    "<br/>\n",
    "‚Ä¢ the idea that is expressed in a work of writing, art, etc.\n",
    "<br/>\n",
    "How do we represent words? Remember, the computer only understands numbers ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution 1: Representing words as discrete symbols\n",
    "** Example: ** Very entertaining and funny!\n",
    "<br/>\n",
    "* We define the vocabulary: \n",
    "\\begin{align}\n",
    "\\mathcal V =\\{'entertaining','funny'\\}\\\\\n",
    "\\end{align}\n",
    "* Embeddings: \n",
    "\\begin{equation}\n",
    "  emb =\n",
    "    \\begin{cases}\n",
    "      X^{entertaining} = [1,0]\\\\\n",
    "      X^{funny} = [0,1]\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "* Vector dimension = number of words in vocabulary (e.g., 500,000)\n",
    "* This Method is called **<font color='red'>One Hot Encoding**: <br/>\n",
    "For a corpus ùê∂ with finite vocabulary, ùëâ and |ùëâ|=ùëõ.\n",
    "<br/> Let emb:ùëâ‚Üí‚Ñï√ó‚Ñï‚ãØ√ó‚Ñï‚âêùëâ¬†ÃÉ  be a map defined by taking every element in ùëâ to an ùëõ component object ùëã¬†‚Éó‚ààùëâ¬†ÃÉ\n",
    " such that: <br/>\n",
    "    \\begin{equation}\n",
    "  X_{i}^{w} =\n",
    "    \\begin{cases}\n",
    "      1, & \\text{if    } idx(w)=i \\\\\n",
    "      0,& \\text{otherwise}\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "DEF_FIGLEN = 7\n",
    "DEF_FIGSIZE = (DEF_FIGLEN, DEF_FIGLEN)\n",
    "\n",
    "def figure(figsize=DEF_FIGSIZE):\n",
    "    return plt.figure(figsize=figsize)\n",
    "\n",
    "def new_blank_plot(ax=None, xlim=(-2, 2), ylim=(-2, 2), axis_color='gray', title=''):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    else:\n",
    "        plt.sca(ax)\n",
    "    ax.axis('equal')\n",
    "    if xlim is not None: ax.set_xlim(xlim[0], xlim[1])\n",
    "    if ylim is not None: ax.set_ylim(ylim[0], ylim[1])\n",
    "    if axis_color is not None:\n",
    "        ax.axhline(color=axis_color)\n",
    "        ax.axvline(color=axis_color)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "def vector(*elems, dim=None):\n",
    "    \"\"\"Exercise: What does this function do?\"\"\"\n",
    "    if dim is not None:\n",
    "        if len(elems) > 0:\n",
    "            assert dim == len(elems), \"Number of supplied elements differs from the requested dimension.\"\n",
    "        else: # No supplied elements\n",
    "            elems = [0.0] * dim\n",
    "    return tuple(elems)\n",
    "\n",
    "\n",
    "def draw_vector2d(v, ax=None, origin=(0, 0), width=0.08, color='black', alpha=1.0,\n",
    "                  **kw_args):\n",
    "    assert len(v) == 2, \"Input vector must be two-dimensional.\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.arrow(origin[0], origin[1], v[0], v[1],\n",
    "             width=width,\n",
    "             facecolor=color,\n",
    "             edgecolor='white',\n",
    "             alpha=alpha,\n",
    "             length_includes_head=True,\n",
    "             **kw_args);\n",
    "    \n",
    "def draw_label2d(p, label, coords=False, ax=None, fontsize=14,\n",
    "                 dp=(0.0, 0.1), horizontalalignment='center', verticalalignment='bottom',\n",
    "                 **kw_args):\n",
    "    assert len(p) == 2, \"Position must be 2-D.\"\n",
    "    if ax is None: ax = plt.gca()\n",
    "    text = '{}'.format(label)\n",
    "    if coords:\n",
    "        text += ' = ({}, {})'.format(p[0], p[1])\n",
    "    ax.text(p[0]+dp[0], p[1]+dp[1], text,\n",
    "            fontsize=fontsize,\n",
    "            horizontalalignment=horizontalalignment,\n",
    "            verticalalignment=verticalalignment,\n",
    "            **kw_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def discrete_word_representation(mytext):\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(mytext.split())\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    return onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vec = discrete_word_representation(processed_positive_review)\n",
    "one_hot_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ac9134898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure()\n",
    "new_blank_plot(title='words as discrete symbols')\n",
    "draw_vector2d(one_hot_vec[0], color='blue')\n",
    "draw_vector2d(one_hot_vec[1], color='red')\n",
    "draw_label2d(one_hot_vec[0], processed_positive_review.split()[0], color='blue', coords=True)\n",
    "draw_label2d(one_hot_vec[1], processed_positive_review.split()[1], color='red', coords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** These 2 vectors are <font color='red'>orthogonal** <br/>\n",
    "** There is no natural notion of <font color='red'> similarity for one-hot vectors!**\n",
    "<h2>  Learn to encode similarity in the vectors themselves !</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution 2: Representing words by their context\n",
    "* ** Distributional semantics: A word‚Äôs meaning is given by the words that frequently appear close-by **\n",
    "* When a word w appears in a text, its context is the set of wordsthat appear nearby (within a fixed-size window).\n",
    "* Use the many contexts of $w$ to build up a representation of $w$\n",
    "<img src=\"images/Context_representation.PNG\", width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font color='red'> <h2> Word Vectors/Embeddings</h2> </font> \n",
    "* We will build a dense vector for each word, chosen so that it is similar to vectors of words that appear in similar contexts.\n",
    "<br/>\n",
    "* **Lower dimensional** -> We consider a word embedding to a D dimensional vector space where D is less than the size of the vocabulary. (in practice it is a linear projection from the embedding space created by one hot encoding and D is no more than 500).\n",
    "<br/>\n",
    "* **‚ÄúSemantic and Syntax‚Äù** -> Word vectors will be allowed to be non-orthogonal. In non-mathematical terms we will preserve the semantic similarity of words by using the direction of the word vectors.\n",
    "\n",
    "<img src=\"images/linear-relationships.svg\", width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Word2Vec Efficient high dimensional word embeddings </h2> </font> \n",
    "Idea:\n",
    "\n",
    "‚Ä¢ We have a large corpus of text \n",
    "\n",
    "‚Ä¢ Every word in a fixed vocabulary is represented by a vector\n",
    "\n",
    "‚Ä¢ Go through each position t in the text, which has a center word c and context (‚Äúoutside‚Äù) words o\n",
    "\n",
    "‚Ä¢ Use the similarity of the word vectors for c and o to calculate the probability of o given c (or vice versa)\n",
    "\n",
    "‚Ä¢ Keep adjusting the word vectors to maximize this probability\n",
    "\n",
    "Example\twindows\tand\tprocess\tfor\tcomputing $P(w_{t+j}|w_t)$\n",
    "<img src=\"images/example_context_rep.png\", width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>token</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>...</th>\n",
       "      <th>v_290</th>\n",
       "      <th>v_291</th>\n",
       "      <th>v_292</th>\n",
       "      <th>v_293</th>\n",
       "      <th>v_294</th>\n",
       "      <th>v_295</th>\n",
       "      <th>v_296</th>\n",
       "      <th>v_297</th>\n",
       "      <th>v_298</th>\n",
       "      <th>v_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>said</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>-0.044189</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193359</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>-0.093262</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>-0.117676</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>-0.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>year</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>-0.037354</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.154297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>-0.156250</td>\n",
       "      <td>-0.146484</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>-0.046631</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.174805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>one</td>\n",
       "      <td>0.045654</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>-0.031006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028931</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>-0.060303</td>\n",
       "      <td>-0.032715</td>\n",
       "      <td>-0.103516</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>-0.095215</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>-0.001884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>would</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>-0.113281</td>\n",
       "      <td>-0.094727</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>-0.029663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>-0.100586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>also</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>-0.006500</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>-0.070801</td>\n",
       "      <td>-0.059326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071777</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>-0.029541</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>-0.152344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  token       v_0       v_1       v_2       v_3       v_4  \\\n",
       "0           0   said -0.009094 -0.044189  0.099609 -0.076172 -0.056641   \n",
       "1           1   year  0.061768  0.257812  0.003677  0.145508 -0.037354   \n",
       "2           2    one  0.045654 -0.145508  0.156250  0.166016  0.109863   \n",
       "3           3  would  0.089355  0.129883  0.212891  0.177734 -0.113281   \n",
       "4           4   also  0.053467  0.012024 -0.006500  0.008545  0.016479   \n",
       "\n",
       "        v_5       v_6       v_7    ...        v_290     v_291     v_292  \\\n",
       "0  0.061523  0.255859 -0.158203    ...    -0.193359  0.029907 -0.093262   \n",
       "1 -0.120117  0.188477 -0.154297    ...    -0.031738  0.056396 -0.156250   \n",
       "2  0.007507  0.073730 -0.031006    ...    -0.028931 -0.013000 -0.060303   \n",
       "3 -0.094727  0.091797 -0.029663    ...    -0.267578  0.087891 -0.071289   \n",
       "4  0.183594 -0.070801 -0.059326    ...    -0.071777 -0.114258  0.040039   \n",
       "\n",
       "      v_293     v_294     v_295     v_296     v_297     v_298     v_299  \n",
       "0  0.053711 -0.117676  0.069824  0.105957  0.144531  0.180664 -0.086914  \n",
       "1 -0.146484  0.007874 -0.133789 -0.046631  0.111816  0.072754 -0.174805  \n",
       "2 -0.032715 -0.103516  0.044678 -0.095215 -0.015869  0.006714 -0.001884  \n",
       "3  0.130859  0.061768  0.187500  0.039307 -0.152344  0.005524 -0.100586  \n",
       "4 -0.078125 -0.029541  0.074219  0.054932 -0.001938  0.032227 -0.152344  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read pre-trained word 2 vec embeddings\n",
    "import pandas as pd\n",
    "embeddings_vocab = pd.read_csv('data/embeddings_vocab.csv')\n",
    "embeddings_vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<font color='red'> <h2> Do not run this cell! </h2> </font> \n",
    "<font color='red'> <h2> The cell below uses t-SNE to project the word embeddings from 300 d to 2D </h2> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 27989 samples in 6.225s...\n",
      "[t-SNE] Computed neighbors for 27989 samples in 1490.779s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 27000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 27989 / 27989\n",
      "[t-SNE] Mean sigma: 0.674907\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 110.711159\n",
      "[t-SNE] Error after 300 iterations: 5.337484\n"
     ]
    }
   ],
   "source": [
    "## Project in 2D for visualization purpose\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(embeddings_vocab.loc[:, 'v_0':])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> <h2> Do not run this cell! </h2> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tsne_embeddings = pd.DataFrame(columns = ['token','v_1','v_2'])\n",
    "tsne_embeddings['token'] = embeddings_vocab['token']\n",
    "tsne_embeddings['v_1'] = tsne_results[:,0]\n",
    "tsne_embeddings['v_2'] = tsne_results[:,1]\n",
    "tsne_embeddings.to_csv('data/tsne_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "colors=['blue','red','green','yellow','brown','orange']\n",
    "def visualize_words_w2v(my_list_of_words):\n",
    "    figure()\n",
    "    for i in range(len(my_list_of_words)):\n",
    "        if my_list_of_words[i] in tsne_embeddings['token'].values:\n",
    "            new_blank_plot(title='words embeddings Word2Vec',xlim=(-3, 3), ylim=(-3, 3))\n",
    "            draw_vector2d(list(tsne_embeddings[tsne_embeddings['token']==my_list_of_words[i]].values[0][1:]), color=colors[i])\n",
    "            draw_label2d(list(tsne_embeddings[tsne_embeddings['token']==my_list_of_words[i]].values[0][1:]), my_list_of_words[i], color=colors[i], coords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_vocab size: (27989, 301)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>...</th>\n",
       "      <th>v_290</th>\n",
       "      <th>v_291</th>\n",
       "      <th>v_292</th>\n",
       "      <th>v_293</th>\n",
       "      <th>v_294</th>\n",
       "      <th>v_295</th>\n",
       "      <th>v_296</th>\n",
       "      <th>v_297</th>\n",
       "      <th>v_298</th>\n",
       "      <th>v_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>-0.044189</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193359</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>-0.093262</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>-0.117676</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>-0.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>-0.037354</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.154297</td>\n",
       "      <td>0.213867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>-0.156250</td>\n",
       "      <td>-0.146484</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>-0.046631</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.174805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>0.045654</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>-0.031006</td>\n",
       "      <td>0.157227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028931</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>-0.060303</td>\n",
       "      <td>-0.032715</td>\n",
       "      <td>-0.103516</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>-0.095215</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>-0.001884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>-0.113281</td>\n",
       "      <td>-0.094727</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>-0.029663</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>-0.100586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>also</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>-0.006500</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>-0.070801</td>\n",
       "      <td>-0.059326</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071777</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>-0.029541</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>-0.152344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   token       v_0       v_1       v_2       v_3       v_4       v_5  \\\n",
       "0   said -0.009094 -0.044189  0.099609 -0.076172 -0.056641  0.061523   \n",
       "1   year  0.061768  0.257812  0.003677  0.145508 -0.037354 -0.120117   \n",
       "2    one  0.045654 -0.145508  0.156250  0.166016  0.109863  0.007507   \n",
       "3  would  0.089355  0.129883  0.212891  0.177734 -0.113281 -0.094727   \n",
       "4   also  0.053467  0.012024 -0.006500  0.008545  0.016479  0.183594   \n",
       "\n",
       "        v_6       v_7       v_8  ...     v_290     v_291     v_292     v_293  \\\n",
       "0  0.255859 -0.158203  0.016602  ... -0.193359  0.029907 -0.093262  0.053711   \n",
       "1  0.188477 -0.154297  0.213867  ... -0.031738  0.056396 -0.156250 -0.146484   \n",
       "2  0.073730 -0.031006  0.157227  ... -0.028931 -0.013000 -0.060303 -0.032715   \n",
       "3  0.091797 -0.029663  0.027710  ... -0.267578  0.087891 -0.071289  0.130859   \n",
       "4 -0.070801 -0.059326  0.014221  ... -0.071777 -0.114258  0.040039 -0.078125   \n",
       "\n",
       "      v_294     v_295     v_296     v_297     v_298     v_299  \n",
       "0 -0.117676  0.069824  0.105957  0.144531  0.180664 -0.086914  \n",
       "1  0.007874 -0.133789 -0.046631  0.111816  0.072754 -0.174805  \n",
       "2 -0.103516  0.044678 -0.095215 -0.015869  0.006714 -0.001884  \n",
       "3  0.061768  0.187500  0.039307 -0.152344  0.005524 -0.100586  \n",
       "4 -0.029541  0.074219  0.054932 -0.001938  0.032227 -0.152344  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the embeddings of the reviews corpus\n",
    "embeddings_vocab = pd.read_csv('data/embeddings_vocab.csv', index_col=0)\n",
    "print('embeddings_vocab size: {}'.format(embeddings_vocab.shape))\n",
    "embeddings_vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ac6ff57f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the 2D embeddings \n",
    "tsne_embeddings = pd.read_csv('data/tsne_embeddings.csv', index_col=0)\n",
    "# visualize a list of words \n",
    "visualize_words_w2v(processed_positive_review.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> NLP Pipeline </h2> </font> \n",
    "<img src=\"images/nlp_pipeline_3.png\", width=1100>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Word2Vec Efficient high dimensional word embeddings </h2> </font> \n",
    "* Take average of the word2vecs of its words (used in first example SVM)\n",
    "* Concatenate the word embeddings to form the sentence (used in second example CNN)\n",
    "* Another approach: Paragraph vector (2014, Quoc Le, Mikolov)\n",
    "  * Extend word2vec to text level\n",
    "  * Also two models: add paragraph vector as the input\n",
    "<img src=\"images/sentence_embed.png\", width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nothing good say scanner image quality poor sl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recieved skin birthday go sansa e excellent fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resolved issues lock pathetically poor gratefu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>work yes well nearly hoped tiny reviews stated...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leaving vacation couple days could find batter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment\n",
       "0  nothing good say scanner image quality poor sl...          0\n",
       "1  recieved skin birthday go sansa e excellent fi...          1\n",
       "2  resolved issues lock pathetically poor gratefu...          0\n",
       "3  work yes well nearly hoped tiny reviews stated...          0\n",
       "4  leaving vacation couple days could find batter...          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the amazon reviews dataset\n",
    "data = pd.read_csv('data/amazon_data_10k.csv', index_col=0)\n",
    "# pre_process the reviews dataset\n",
    "data['reviews'] = data['reviews'].apply(lambda x: pre_process(x))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-730daf376f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf_unigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_unigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf_unigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_unigram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'reviews'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf_unigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_unigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdf_unigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_unigram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdf_unigram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     56\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                          validate=validate)\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             concat_axis=0, copy=self.copy)\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5202\u001b[0m             b = make_block(\n\u001b[0;32m-> 5203\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5204\u001b[0m                 placement=placement)\n\u001b[1;32m   5205\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5330\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[1;32m   5331\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[0;32m-> 5332\u001b[0;31m                  for ju in join_units]\n\u001b[0m\u001b[1;32m   5333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5330\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[1;32m   5331\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[0;32m-> 5332\u001b[0;31m                  for ju in join_units]\n\u001b[0m\u001b[1;32m   5333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m   5630\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5631\u001b[0m                 values = algos.take_nd(values, indexer, axis=ax,\n\u001b[0;32m-> 5632\u001b[0;31m                                        fill_value=fill_value)\n\u001b[0m\u001b[1;32m   5633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5634\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Represent reviews as average of words embeddings\n",
    "\n",
    "all_review = []\n",
    "all_unigram = []\n",
    "\n",
    "for a in data['reviews']:\n",
    "    unigram = []\n",
    "    review = []\n",
    "    unigram = a.split()\n",
    "    review = [a] * len(unigram)\n",
    "    all_review.extend(review)\n",
    "    all_unigram.extend(unigram)\n",
    "\n",
    "\n",
    "df_unigram = pd.DataFrame({'reviews': all_review, 'token': all_unigram})\n",
    "df_unigram = pd.merge(data, df_unigram, how='right', on=['reviews'])\n",
    "df_unigram = df_unigram.drop_duplicates(subset = ['reviews','token'])\n",
    "df_unigram = pd.merge(embeddings_vocab, df_unigram, how='right', on=['token']).dropna()\n",
    "df_unigram = df_unigram.groupby(['reviews'],as_index = False).mean()\n",
    "df_unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Simple Classifier ‚Äì From word representation to modeling </h2> </font> \n",
    "**Linear SVM and Logistic Based Classification**\n",
    "* Pre-processing converts words to features and creates new features based on word count\n",
    "* Text vectorization  outputs  the features to numerical vectors. Ex count vectors, TF-IDF vectors\n",
    "* For classification problems, vector spaced based ML methods can be applied to find decision boundary between two classes .  Notable example SVM.\n",
    "* Linear SVM defines the criterion that maximally separates the two classes, allowing users to adjust cost and penalty parameters on misclassification to suit business problems.\n",
    "<img src=\"images/SVM_hyperplane.png\", width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Split the dataset to train and test (80% for training and 20% for testing)\n",
    "\n",
    "## Fit the linear SVC on the training data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(df_unigram[df_unigram.columns[1:301]],df_unigram['sentiment'],test_size=0.2)\n",
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted 82.97% correctly from the test dataset \n"
     ]
    }
   ],
   "source": [
    "# Test the Linar SVC model on the test data\n",
    "# WE use the accuracy defined as ratio of correctly predicted data by the overall data\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Test_predictions = clf.predict(Test_X)\n",
    "print(\"The model predicted {0:.2f}% correctly from the test dataset \".format(accuracy_score(Test_Y,Test_predictions)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Cassify the sentiment of your own review using the linear SVC model! </h2> </font> \n",
    "The linear SVM is able to correctly classify **83.29%** of the amazon test dataset reviews.\n",
    "<br/>\n",
    "You can use the function below to find out what the model thinks of your review!!\n",
    "\n",
    "1) Write your review\n",
    "\n",
    "2) Preprocess your review\n",
    "\n",
    "3) Call the function get_svc_class(my_processed_review) to ge the result of the SVM model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Classify the sentiment of my comment\n",
    "import numpy as np\n",
    "def get_svc_class(my_processed_review):\n",
    "    avg_embed = []\n",
    "    for i in my_processed_review.split():\n",
    "        if i in embeddings_vocab['token'].values:\n",
    "            avg_embed.append(embeddings_vocab[embeddings_vocab['token']=='happy'].values[0][1:])\n",
    "    my_prediction = clf.predict(np.mean(avg_embed,axis=0).reshape(1, -1))\n",
    "    if my_prediction == 1:\n",
    "        print('The model predicted that the review is positive')\n",
    "    else:\n",
    "        print('The model predicted that the review is negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted that the review is positive\n"
     ]
    }
   ],
   "source": [
    "get_svc_class(processed_positive_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Neural Network classifier- Convolution neural networks</h2> </font> \n",
    "* Traditionally, CNNs are used to analyze images and are made up of one or more convolutional layers.\n",
    "\n",
    "* Main idea here is to use multiple filters of different sizes that can look at bi-grams, tri-grams, n-grams.\n",
    "\n",
    "* Fast to train, works well, but fails to capture longer dependencies.\n",
    "\n",
    "<img src=\"images/CNN.png\", width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make the max word length to be constant\n",
    "MAX_WORDS = embeddings_vocab.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EMBEDDING_DIM = 300\n",
    "filter_sizes = [1,2,3]\n",
    "num_filters = 20\n",
    "drop = 0.3\n",
    "batch_size = 64\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words : 81816\n"
     ]
    }
   ],
   "source": [
    "tokenizer  = Tokenizer(num_words = MAX_WORDS)\n",
    "tokenizer.fit_on_texts(data['reviews'])\n",
    "sequences =  tokenizer.texts_to_sequences(data['reviews'])\n",
    "word_index = tokenizer.word_index\n",
    "print(\"unique words : {}\".format(len(word_index)))\n",
    "data_padded = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "## Split data to train, validation and test\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(data_padded, data['sentiment'],test_size=0.2)\n",
    "Train_X, Val_X, Train_Y, Val_Y = train_test_split(Train_X, Train_Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## Create embeddings Matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in embeddings_vocab['token'].values:\n",
    "        embedding_matrix[i] = embeddings_vocab[embeddings_vocab['token']==word].values[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0428 18:48:49.692382 140403222415168 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0428 18:48:54.183534 140403222415168 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0428 18:48:54.232224 140403222415168 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0428 18:48:54.246148 140403222415168 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0428 18:48:54.246721 140403222415168 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0428 18:48:54.963502 140403222415168 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0428 18:48:54.980294 140403222415168 deprecation.py:506] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0428 18:48:55.016230 140403222415168 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0428 18:48:55.024156 140403222415168 deprecation.py:323] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-NLP-DevEnv01/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 200, 300)\n",
      "(?, 200, 300, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     24545100    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 200, 300, 1)  0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 200, 1, 20)   6020        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 199, 1, 20)   12020       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 198, 1, 20)   18020       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 20)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 20)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 20)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 1, 20)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 60)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 60)           0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            61          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,581,221\n",
      "Trainable params: 36,121\n",
      "Non-trainable params: 24,545,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(inputs)\n",
    "print(embedding.shape)\n",
    "reshape = Reshape((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(embedding)\n",
    "print(reshape.shape)\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(1,activation = 'sigmoid')(dropout)\n",
    "# this creates a model that includes\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "checkpoint = ModelCheckpoint('weights_cnn_sentece.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "model.compile(optimizer=Adam(lr = 1e-2), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22400 samples, validate on 5600 samples\n",
      "Epoch 1/20\n",
      "22400/22400 [==============================] - 5s 224us/step - loss: 0.4016 - acc: 0.8163 - val_loss: 0.3182 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86143, saving model to weights_cnn_sentece.hdf5\n",
      "Epoch 2/20\n",
      "22400/22400 [==============================] - 5s 205us/step - loss: 0.3271 - acc: 0.8592 - val_loss: 0.3049 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86143 to 0.87161, saving model to weights_cnn_sentece.hdf5\n",
      "Epoch 3/20\n",
      "22400/22400 [==============================] - 5s 206us/step - loss: 0.2937 - acc: 0.8751 - val_loss: 0.3131 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.87161\n",
      "Epoch 4/20\n",
      "22400/22400 [==============================] - 4s 199us/step - loss: 0.2716 - acc: 0.8888 - val_loss: 0.3175 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.87161\n",
      "Epoch 5/20\n",
      "22400/22400 [==============================] - 4s 198us/step - loss: 0.2535 - acc: 0.8958 - val_loss: 0.3068 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87161 to 0.87357, saving model to weights_cnn_sentece.hdf5\n",
      "Epoch 6/20\n",
      "22400/22400 [==============================] - 4s 195us/step - loss: 0.2430 - acc: 0.9045 - val_loss: 0.2996 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.87357 to 0.87839, saving model to weights_cnn_sentece.hdf5\n",
      "Epoch 7/20\n",
      "22400/22400 [==============================] - 4s 195us/step - loss: 0.2169 - acc: 0.9125 - val_loss: 0.3147 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87839\n",
      "Epoch 8/20\n",
      "22400/22400 [==============================] - 4s 199us/step - loss: 0.2098 - acc: 0.9153 - val_loss: 0.3125 - val_acc: 0.8775\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87839\n",
      "Epoch 9/20\n",
      "22400/22400 [==============================] - 4s 195us/step - loss: 0.1922 - acc: 0.9223 - val_loss: 0.3111 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.87839\n",
      "Epoch 10/20\n",
      "22400/22400 [==============================] - 4s 200us/step - loss: 0.1866 - acc: 0.9246 - val_loss: 0.3315 - val_acc: 0.8768\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.87839\n",
      "Epoch 11/20\n",
      "22400/22400 [==============================] - 4s 197us/step - loss: 0.1800 - acc: 0.9301 - val_loss: 0.3436 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.87839\n",
      "Epoch 12/20\n",
      "22400/22400 [==============================] - 4s 192us/step - loss: 0.1668 - acc: 0.9358 - val_loss: 0.3491 - val_acc: 0.8691\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.87839\n",
      "Epoch 13/20\n",
      "22400/22400 [==============================] - 4s 195us/step - loss: 0.1641 - acc: 0.9356 - val_loss: 0.3504 - val_acc: 0.8761\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.87839\n",
      "Epoch 14/20\n",
      "22400/22400 [==============================] - 5s 201us/step - loss: 0.1534 - acc: 0.9405 - val_loss: 0.3607 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.87839\n",
      "Epoch 15/20\n",
      "22400/22400 [==============================] - 4s 198us/step - loss: 0.1530 - acc: 0.9403 - val_loss: 0.3682 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.87839\n",
      "Epoch 16/20\n",
      "22400/22400 [==============================] - 5s 203us/step - loss: 0.1410 - acc: 0.9447 - val_loss: 0.3804 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.87839\n",
      "Epoch 17/20\n",
      "22400/22400 [==============================] - 5s 206us/step - loss: 0.1426 - acc: 0.9463 - val_loss: 0.3843 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.87839\n",
      "Epoch 18/20\n",
      "22400/22400 [==============================] - 5s 208us/step - loss: 0.1366 - acc: 0.9482 - val_loss: 0.3914 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.87839\n",
      "Epoch 19/20\n",
      "22400/22400 [==============================] - 5s 209us/step - loss: 0.1344 - acc: 0.9487 - val_loss: 0.4258 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.87839\n",
      "Epoch 20/20\n",
      "22400/22400 [==============================] - 5s 206us/step - loss: 0.1260 - acc: 0.9527 - val_loss: 0.4211 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.87839\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Train_X, Train_Y, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(Val_X, Val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('weights_cnn_sentece.hdf5')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted 86.93% correctly from the test dataset \n"
     ]
    }
   ],
   "source": [
    "print(\"The model predicted {0:.2f}% correctly from the test dataset \".format(accuracy_score(Test_Y, (model.predict(Test_X) > 0.5).astype(int))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
